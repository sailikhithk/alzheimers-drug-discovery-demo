{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Python Libraries Primer for Drug Discovery\n## Prerequisites for the Alzheimer's Drug Discovery Project\n\nThis notebook introduces the key Python libraries used in computational drug discovery. Work through these examples to understand each library before diving into the main project.\n\n**Libraries Covered:**\n1. **NumPy** \u2014 Numerical computing\n2. **Pandas** \u2014 Data manipulation\n3. **Matplotlib & Seaborn** \u2014 Visualization\n4. **RDKit** \u2014 Chemistry/molecular analysis\n5. **Scikit-learn** \u2014 Machine learning\n\n**Learning Objectives:**\n- Load and manipulate data with pandas\n- Perform numerical operations with numpy\n- Create visualizations\n- Parse molecular structures with RDKit\n- Build basic ML models"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 0. Setup: Install Required Libraries"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Install all required libraries using uv (faster!)\n!pip install uv -q\n!uv pip install --system numpy pandas matplotlib seaborn rdkit scikit-learn --quiet\nprint(\"\u2713 All libraries installed!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 1. NumPy \u2014 Numerical Computing\n\nNumPy is the foundation for numerical computing in Python. It provides fast array operations."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import numpy as np\nprint(f\"NumPy version: {np.__version__}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1.1 Creating Arrays"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create arrays from lists\nic50_values = np.array([100, 500, 1000, 5000, 10000, 50000])\nprint(\"IC50 values (nM):\", ic50_values)\nprint(\"Shape:\", ic50_values.shape)\nprint(\"Data type:\", ic50_values.dtype)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create special arrays\nzeros = np.zeros(5)\nones = np.ones(5)\nrange_arr = np.arange(0, 10, 2)  # start, stop, step\nlinspace = np.linspace(0, 1, 5)  # start, stop, num_points\n\nprint(\"Zeros:\", zeros)\nprint(\"Ones:\", ones)\nprint(\"Range:\", range_arr)\nprint(\"Linspace:\", linspace)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1.2 Array Operations (Vectorized)\n\nNumPy operations work on entire arrays at once \u2014 much faster than loops!"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Convert IC50 (nM) to pIC50\n# pIC50 = -log10(IC50 in Molar)\n# IC50 in Molar = IC50 in nM * 1e-9\n\nic50_molar = ic50_values * 1e-9\npIC50 = -np.log10(ic50_molar)\n\nprint(\"IC50 (nM):\", ic50_values)\nprint(\"IC50 (M):\", ic50_molar)\nprint(\"pIC50:\", pIC50)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Statistical operations\nprint(f\"Mean pIC50: {np.mean(pIC50):.2f}\")\nprint(f\"Std pIC50: {np.std(pIC50):.2f}\")\nprint(f\"Min pIC50: {np.min(pIC50):.2f}\")\nprint(f\"Max pIC50: {np.max(pIC50):.2f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1.3 Boolean Indexing (Filtering)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Find \"active\" compounds (IC50 < 1000 nM, or pIC50 > 6)\nactive_mask = pIC50 > 6\nprint(\"Active mask:\", active_mask)\nprint(\"Active pIC50 values:\", pIC50[active_mask])\nprint(\"Number of active compounds:\", np.sum(active_mask))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 2. Pandas \u2014 Data Manipulation\n\nPandas is essential for working with tabular data (like CSV files)."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import pandas as pd\nprint(f\"Pandas version: {pd.__version__}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.1 Creating DataFrames"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create a DataFrame from a dictionary\ndata = {\n    'molecule_id': ['MOL001', 'MOL002', 'MOL003', 'MOL004', 'MOL005', 'MOL006'],\n    'smiles': ['CCO', 'CCCO', 'CCCCO', 'CC(C)O', 'CCOCC', 'c1ccccc1'],\n    'ic50_nM': [100, 500, 1000, 5000, 10000, 50000],\n    'molecular_weight': [46.07, 60.10, 74.12, 60.10, 74.12, 78.11]\n}\n\ndf = pd.DataFrame(data)\ndf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.2 Basic DataFrame Operations"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Basic info\nprint(\"Shape:\", df.shape)\nprint(\"\\nColumn types:\")\nprint(df.dtypes)\nprint(\"\\nBasic statistics:\")\ndf.describe()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Access columns\nprint(\"SMILES column:\")\nprint(df['smiles'])",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Access rows by index\nprint(\"First row:\")\nprint(df.iloc[0])\nprint(\"\\nFirst 3 rows:\")\ndf.head(3)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.3 Adding New Columns"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Calculate pIC50 and add as new column\ndf['pIC50'] = -np.log10(df['ic50_nM'] * 1e-9)\n\n# Add bioactivity class\ndef classify_activity(ic50):\n    if ic50 <= 1000:\n        return 'active'\n    elif ic50 >= 10000:\n        return 'inactive'\n    else:\n        return 'intermediate'\n\ndf['class'] = df['ic50_nM'].apply(classify_activity)\ndf",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.4 Filtering Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Filter for active compounds only\nactive_df = df[df['class'] == 'active']\nprint(\"Active compounds:\")\nactive_df",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Multiple conditions\n# Active AND molecular weight < 70\nfiltered = df[(df['class'] == 'active') & (df['molecular_weight'] < 70)]\nprint(\"Active compounds with MW < 70:\")\nfiltered",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.5 Grouping and Aggregation"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Count by class\nprint(\"Compounds per class:\")\nprint(df['class'].value_counts())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Group statistics\nprint(\"\\nMean pIC50 by class:\")\nprint(df.groupby('class')['pIC50'].mean())",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2.6 Reading/Writing CSV Files"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Save to CSV\ndf.to_csv('sample_bioactivity.csv', index=False)\nprint(\"Saved to sample_bioactivity.csv\")\n\n# Read back\ndf_loaded = pd.read_csv('sample_bioactivity.csv')\ndf_loaded.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 3. Matplotlib & Seaborn \u2014 Visualization\n\nCreating plots to understand your data."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set style\nsns.set_style(\"whitegrid\")\nprint(f\"Matplotlib version: {plt.matplotlib.__version__}\")\nprint(f\"Seaborn version: {sns.__version__}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.1 Bar Plot \u2014 Class Distribution"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Count plot for bioactivity classes\nplt.figure(figsize=(8, 5))\nsns.countplot(data=df, x='class', order=['active', 'intermediate', 'inactive'],\n              palette=['green', 'orange', 'red'])\nplt.title('Distribution of Bioactivity Classes')\nplt.xlabel('Bioactivity Class')\nplt.ylabel('Count')\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.2 Box Plot \u2014 pIC50 by Class"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "plt.figure(figsize=(8, 5))\nsns.boxplot(data=df, x='class', y='pIC50', \n            order=['active', 'intermediate', 'inactive'],\n            palette=['green', 'orange', 'red'])\nplt.title('pIC50 Distribution by Bioactivity Class')\nplt.xlabel('Bioactivity Class')\nplt.ylabel('pIC50')\nplt.axhline(y=6, color='blue', linestyle='--', label='Active threshold (pIC50=6)')\nplt.legend()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.3 Scatter Plot \u2014 MW vs pIC50"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "plt.figure(figsize=(8, 6))\ncolors = {'active': 'green', 'intermediate': 'orange', 'inactive': 'red'}\nfor cls in ['active', 'intermediate', 'inactive']:\n    subset = df[df['class'] == cls]\n    plt.scatter(subset['molecular_weight'], subset['pIC50'], \n                c=colors[cls], label=cls, s=100, alpha=0.7)\n\nplt.xlabel('Molecular Weight (Da)')\nplt.ylabel('pIC50')\nplt.title('Chemical Space: MW vs pIC50')\nplt.legend()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3.4 Histogram \u2014 Distribution"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n# pIC50 distribution\naxes[0].hist(df['pIC50'], bins=10, color='steelblue', edgecolor='black')\naxes[0].set_xlabel('pIC50')\naxes[0].set_ylabel('Frequency')\naxes[0].set_title('pIC50 Distribution')\n\n# Molecular weight distribution\naxes[1].hist(df['molecular_weight'], bins=10, color='coral', edgecolor='black')\naxes[1].set_xlabel('Molecular Weight (Da)')\naxes[1].set_ylabel('Frequency')\naxes[1].set_title('Molecular Weight Distribution')\n\nplt.tight_layout()\nplt.show()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 4. RDKit \u2014 Chemistry & Molecular Analysis\n\nRDKit is the go-to library for cheminformatics in Python."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from rdkit import Chem\nfrom rdkit.Chem import Descriptors, Lipinski, Draw\nprint(\"RDKit imported successfully!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.1 Parsing SMILES Strings\n\nSMILES (Simplified Molecular Input Line Entry System) is a text representation of molecules."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Parse a SMILES string into a molecule object\nsmiles = \"CCO\"  # Ethanol\nmol = Chem.MolFromSmiles(smiles)\n\nprint(f\"SMILES: {smiles}\")\nprint(f\"Molecule object: {mol}\")\nprint(f\"Number of atoms: {mol.GetNumAtoms()}\")\nprint(f\"Number of bonds: {mol.GetNumBonds()}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# More complex molecule: Aspirin\naspirin_smiles = \"CC(=O)OC1=CC=CC=C1C(=O)O\"\naspirin = Chem.MolFromSmiles(aspirin_smiles)\n\nprint(f\"Aspirin SMILES: {aspirin_smiles}\")\nprint(f\"Number of atoms: {aspirin.GetNumAtoms()}\")\nprint(f\"Number of bonds: {aspirin.GetNumBonds()}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.2 Calculating Molecular Descriptors"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Calculate Lipinski descriptors for Aspirin\nmol = aspirin\n\nmw = Descriptors.MolWt(mol)\nlogp = Descriptors.MolLogP(mol)\nhbd = Lipinski.NumHDonors(mol)\nhba = Lipinski.NumHAcceptors(mol)\n\nprint(\"Aspirin Lipinski Descriptors:\")\nprint(f\"  Molecular Weight: {mw:.2f} Da (Rule: < 500)\")\nprint(f\"  LogP: {logp:.2f} (Rule: < 5)\")\nprint(f\"  H-Bond Donors: {hbd} (Rule: \u2264 5)\")\nprint(f\"  H-Bond Acceptors: {hba} (Rule: \u2264 10)\")\n\n# Check if drug-like\nviolations = 0\nif mw > 500: violations += 1\nif logp > 5: violations += 1\nif hbd > 5: violations += 1\nif hba > 10: violations += 1\nprint(f\"\\nLipinski violations: {violations} (Drug-like if \u2264 1)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.3 Calculate Descriptors for Multiple Molecules"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Function to calculate Lipinski descriptors\ndef calculate_lipinski(smiles):\n    mol = Chem.MolFromSmiles(smiles)\n    if mol is None:\n        return None, None, None, None\n    return (\n        Descriptors.MolWt(mol),\n        Descriptors.MolLogP(mol),\n        Lipinski.NumHDonors(mol),\n        Lipinski.NumHAcceptors(mol)\n    )\n\n# Apply to our dataframe\nlipinski_data = df['smiles'].apply(calculate_lipinski)\ndf['MW'] = [x[0] for x in lipinski_data]\ndf['LogP'] = [x[1] for x in lipinski_data]\ndf['HBD'] = [x[2] for x in lipinski_data]\ndf['HBA'] = [x[3] for x in lipinski_data]\n\ndf[['molecule_id', 'smiles', 'MW', 'LogP', 'HBD', 'HBA']]",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4.4 Visualize Molecules"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Draw a single molecule\nmol = Chem.MolFromSmiles(\"c1ccccc1\")  # Benzene\nDraw.MolToImage(mol, size=(200, 200))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Draw multiple molecules in a grid\nmols = [Chem.MolFromSmiles(s) for s in df['smiles']]\nlegends = df['molecule_id'].tolist()\nDraw.MolsToGridImage(mols, molsPerRow=3, subImgSize=(200, 200), legends=legends)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 5. Scikit-learn \u2014 Machine Learning\n\nBuilding predictive models."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nimport numpy as np\n\nprint(\"Scikit-learn imported successfully!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.1 Prepare Data for ML"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Features (X) and Target (Y)\n# We'll predict pIC50 from molecular descriptors\nX = df[['MW', 'LogP', 'HBD', 'HBA']].values\nY = df['pIC50'].values\n\nprint(\"Features (X) shape:\", X.shape)\nprint(\"Target (Y) shape:\", Y.shape)\nprint(\"\\nFeature matrix:\")\nprint(X)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.2 Train/Test Split"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Split data: 80% train, 20% test\nX_train, X_test, Y_train, Y_test = train_test_split(\n    X, Y, test_size=0.2, random_state=42\n)\n\nprint(f\"Training samples: {len(X_train)}\")\nprint(f\"Test samples: {len(X_test)}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.3 Train a Model"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create and train a Random Forest model\nmodel = RandomForestRegressor(n_estimators=100, random_state=42)\nmodel.fit(X_train, Y_train)\n\nprint(\"Model trained!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.4 Make Predictions and Evaluate"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Predict on test set\nY_pred = model.predict(X_test)\n\n# Calculate metrics\nr2 = r2_score(Y_test, Y_pred)\nrmse = np.sqrt(mean_squared_error(Y_test, Y_pred))\n\nprint(f\"R\u00b2 Score: {r2:.4f}\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"\\nActual vs Predicted:\")\nfor actual, pred in zip(Y_test, Y_pred):\n    print(f\"  Actual: {actual:.2f}, Predicted: {pred:.2f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.5 Cross-Validation"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# 3-fold cross-validation (small dataset, so 3 folds)\ncv_scores = cross_val_score(model, X, Y, cv=3, scoring='r2')\n\nprint(\"Cross-Validation Results:\")\nprint(f\"  R\u00b2 scores: {cv_scores}\")\nprint(f\"  Mean R\u00b2: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5.6 Feature Importance"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Which features are most important?\nfeature_names = ['MW', 'LogP', 'HBD', 'HBA']\nimportances = model.feature_importances_\n\nplt.figure(figsize=(8, 4))\nplt.barh(feature_names, importances, color='steelblue')\nplt.xlabel('Importance')\nplt.title('Feature Importance for pIC50 Prediction')\nplt.show()\n\nprint(\"\\nFeature Importances:\")\nfor name, imp in zip(feature_names, importances):\n    print(f\"  {name}: {imp:.4f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 6. ChEMBL Web Resource Client \u2014 Database Access\n\nChEMBL is the world's largest open database of bioactive molecules. The `chembl_webresource_client` lets us query it programmatically."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!uv pip install --system chembl_webresource_client --quiet\nfrom chembl_webresource_client.new_client import new_client\nprint(\"ChEMBL client imported!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6.1 Search for Target Proteins"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Search for a target by name\ntarget = new_client.target\ntarget_query = target.search('beta amyloid')\n\n# Convert to DataFrame\ntargets_df = pd.DataFrame.from_dict(target_query)\nprint(f\"Found {len(targets_df)} targets related to 'beta amyloid'\")\ntargets_df[['target_chembl_id', 'pref_name', 'target_type', 'organism']].head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6.2 Get Bioactivity Data for a Target"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Get bioactivity data for a specific target\n# CHEMBL2487 = Beta amyloid A4 protein\nactivity = new_client.activity\nbioactivities = activity.filter(target_chembl_id='CHEMBL2487').filter(standard_type='IC50')\n\n# This can be slow, so let's just get first 10 for demo\nbioactivities_list = list(bioactivities[:10])\nprint(f\"Retrieved {len(bioactivities_list)} bioactivity records\")\n\n# Convert to DataFrame\nbio_df = pd.DataFrame.from_dict(bioactivities_list)\nbio_df[['molecule_chembl_id', 'canonical_smiles', 'standard_value', 'standard_units']].head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 6.3 Search for Molecules"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Search for a specific molecule by name\nmolecule = new_client.molecule\naspirin = molecule.search('aspirin')[0]\n\nprint(\"Aspirin from ChEMBL:\")\nprint(f\"  ChEMBL ID: {aspirin['molecule_chembl_id']}\")\nprint(f\"  Name: {aspirin['pref_name']}\")\nprint(f\"  SMILES: {aspirin['molecule_structures']['canonical_smiles']}\")\nprint(f\"  MW: {aspirin['molecule_properties']['full_mwt']}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 7. OpenPyXL \u2014 Excel File Handling\n\nPandas uses openpyxl to read/write Excel files (.xlsx)."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!uv pip install --system openpyxl --quiet\nimport openpyxl\nprint(f\"openpyxl version: {openpyxl.__version__}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7.1 Read Excel Files with Pandas"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create a sample Excel file first\nsample_data = pd.DataFrame({\n    'Molecule': ['Aspirin', 'Ibuprofen', 'Caffeine'],\n    'MW': [180.16, 206.29, 194.19],\n    'IC50_nM': [500, 1200, 8000]\n})\nsample_data.to_excel('sample_drugs.xlsx', index=False, sheet_name='Drugs')\nprint(\"Created sample_drugs.xlsx\")\n\n# Read it back\ndf_excel = pd.read_excel('sample_drugs.xlsx', sheet_name='Drugs')\ndf_excel",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 7.2 Direct openpyxl Usage (Advanced)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Load workbook directly\nwb = openpyxl.load_workbook('sample_drugs.xlsx')\nprint(f\"Sheet names: {wb.sheetnames}\")\n\n# Access a specific sheet\nsheet = wb['Drugs']\nprint(f\"\\nCell A1: {sheet['A1'].value}\")\nprint(f\"Cell B2: {sheet['B2'].value}\")\n\n# Iterate through rows\nprint(\"\\nAll data:\")\nfor row in sheet.iter_rows(values_only=True):\n    print(row)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 8. SciPy \u2014 Statistical Tests\n\nSciPy provides statistical functions like the Mann-Whitney U test."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "from scipy import stats\nprint(\"SciPy stats imported!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8.1 Mann-Whitney U Test\n\nA non-parametric test to compare two independent groups. Used to check if active and inactive compounds have significantly different properties."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create sample data: pIC50 values for active vs inactive compounds\nactive_pIC50 = np.array([7.5, 8.0, 7.2, 8.5, 7.8, 8.2, 7.0, 8.8])\ninactive_pIC50 = np.array([4.5, 4.8, 5.0, 4.2, 4.9, 5.2, 4.0, 4.7])\n\nprint(\"Active pIC50:\", active_pIC50)\nprint(\"Inactive pIC50:\", inactive_pIC50)\nprint(f\"\\nActive mean: {active_pIC50.mean():.2f}\")\nprint(f\"Inactive mean: {inactive_pIC50.mean():.2f}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Perform Mann-Whitney U test\nstatistic, p_value = stats.mannwhitneyu(active_pIC50, inactive_pIC50)\n\nprint(\"Mann-Whitney U Test Results:\")\nprint(f\"  U-statistic: {statistic}\")\nprint(f\"  P-value: {p_value:.2e}\")\nprint(f\"\\nInterpretation:\")\nif p_value < 0.05:\n    print(\"  \u2713 Significant difference (p < 0.05)\")\n    print(\"  Active and inactive compounds have different pIC50 distributions\")\nelse:\n    print(\"  \u2717 No significant difference (p >= 0.05)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 8.2 Other Useful Statistical Functions"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Pearson correlation\nx = np.array([1, 2, 3, 4, 5])\ny = np.array([2, 4, 5, 4, 5])\ncorr, p = stats.pearsonr(x, y)\nprint(f\"Pearson correlation: r={corr:.3f}, p={p:.3f}\")\n\n# T-test (parametric alternative to Mann-Whitney)\nt_stat, t_p = stats.ttest_ind(active_pIC50, inactive_pIC50)\nprint(f\"\\nT-test: t={t_stat:.3f}, p={t_p:.2e}\")\n\n# Shapiro-Wilk test for normality\nstat, p = stats.shapiro(active_pIC50)\nprint(f\"\\nShapiro-Wilk (active): W={stat:.3f}, p={p:.3f}\")\nprint(f\"  Normal distribution: {'Yes' if p > 0.05 else 'No'}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 9. PaDELPy \u2014 Molecular Fingerprints\n\nPaDEL calculates molecular fingerprints (881-bit PubChem fingerprints) from SMILES."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!uv pip install --system padelpy --quiet\nfrom padelpy import from_smiles\nprint(\"PaDELPy imported!\")\nprint(\"Note: PaDEL requires Java to be installed\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9.1 Calculate Fingerprints from SMILES"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Check if Java is available\nimport subprocess\ntry:\n    result = subprocess.run(['java', '-version'], capture_output=True, text=True)\n    print(\"Java is available!\")\n    java_available = True\nexcept:\n    print(\"Java not found - PaDEL won't work without it\")\n    java_available = False",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Calculate fingerprints for a molecule (if Java available)\nif java_available:\n    try:\n        # This calculates PubChem fingerprints\n        smiles = \"CCO\"  # Ethanol\n        descriptors = from_smiles(smiles, fingerprints=True, descriptors=False)\n        \n        print(f\"SMILES: {smiles}\")\n        print(f\"Number of fingerprint bits: {len(descriptors)}\")\n        print(f\"First 10 fingerprint values: {list(descriptors.values())[:10]}\")\n    except Exception as e:\n        print(f\"PaDEL error: {e}\")\n        print(\"This is normal if Java/PaDEL isn't properly configured\")\nelse:\n    print(\"Skipping PaDEL demo - Java not available\")\n    print(\"\\nIn the main notebook, we use pre-computed fingerprints from a CSV file\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 9.2 Understanding Fingerprints\n\nMolecular fingerprints are binary vectors (0s and 1s) representing molecular substructures:\n\n| Bit | Meaning | Example |\n|-----|---------|---------|\n| 0 | Has \u22651 Carbon | Most organic molecules |\n| 1 | Has \u22652 Carbons | Ethanol (CCO) |\n| ... | ... | ... |\n| 115 | Has benzene ring | Aspirin |\n| ... | ... | ... |\n| 880 | Specific SMARTS pattern | Complex substructure |\n\n**Why fingerprints?**\n- Convert molecular structure to numbers for ML\n- Each bit represents presence/absence of a substructure\n- 881 bits = 881 features for machine learning"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 10. LazyPredict \u2014 Automated Model Benchmarking\n\nLazyPredict runs 30+ ML algorithms automatically and ranks them by performance."
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "!uv pip install --system lazypredict xgboost lightgbm --quiet\nfrom lazypredict.Supervised import LazyRegressor\nprint(\"LazyPredict imported!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10.1 Quick Model Comparison"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Create sample dataset\nnp.random.seed(42)\nn_samples = 100\n\n# Features: MW, LogP, HBD, HBA (simulated)\nX_demo = np.random.rand(n_samples, 4) * np.array([300, 5, 5, 10]) + np.array([200, 0, 0, 0])\n# Target: pIC50 (simulated with some relationship to features)\nY_demo = 5 + 0.005 * X_demo[:, 0] - 0.3 * X_demo[:, 1] + np.random.randn(n_samples) * 0.5\n\nprint(f\"Features shape: {X_demo.shape}\")\nprint(f\"Target shape: {Y_demo.shape}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Split data\nX_train_demo, X_test_demo, Y_train_demo, Y_test_demo = train_test_split(\n    X_demo, Y_demo, test_size=0.2, random_state=42\n)\n\n# Run LazyPredict\nimport warnings\nwarnings.filterwarnings('ignore')\n\nreg = LazyRegressor(verbose=0, ignore_warnings=True, custom_metric=None)\nmodels, predictions = reg.fit(X_train_demo, X_test_demo, Y_train_demo, Y_test_demo)\n\nprint(\"Top 10 Models by R\u00b2 Score:\")\nmodels.head(10)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 10.2 Understanding LazyPredict Output\n\n| Column | Meaning |\n|--------|---------|\n| Adjusted R-Squared | R\u00b2 adjusted for number of features |\n| R-Squared | Proportion of variance explained (0-1) |\n| RMSE | Root Mean Squared Error (lower = better) |\n| Time Taken | Training time in seconds |\n\n**Key insight:** LazyPredict helps you quickly identify which algorithms work best for your data before spending time on hyperparameter tuning."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 11. Cleanup"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Remove temporary files\nimport os\nif os.path.exists('sample_bioactivity.csv'):\n    os.remove('sample_bioactivity.csv')\n    print(\"Cleaned up temporary files!\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n# 12. Quick Reference\n\n## NumPy\n```python\nimport numpy as np\narr = np.array([1, 2, 3])\nnp.mean(arr), np.std(arr), np.log10(arr)\n```\n\n## Pandas\n```python\nimport pandas as pd\ndf = pd.read_csv('file.csv')\ndf.head(), df.describe(), df['column']\ndf[df['column'] > value]  # filtering\ndf.groupby('column').mean()\n```\n\n## Matplotlib/Seaborn\n```python\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(8, 6))\nsns.boxplot(data=df, x='class', y='value')\nplt.show()\n```\n\n## RDKit\n```python\nfrom rdkit import Chem\nfrom rdkit.Chem import Descriptors, Lipinski\nmol = Chem.MolFromSmiles('CCO')\nmw = Descriptors.MolWt(mol)\nlogp = Descriptors.MolLogP(mol)\n```\n\n## Scikit-learn\n```python\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\nmodel = RandomForestRegressor()\nmodel.fit(X_train, Y_train)\npredictions = model.predict(X_test)\n```\n\n---\n\n**Next Step:** You're now ready for the main **Alzheimer's Drug Discovery** notebook!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}