@startuml Alzheimer's Drug Discovery Workflow
!theme plain
skinparam backgroundColor #FFFFFF
skinparam defaultFontSize 11
skinparam defaultFontName Arial

title Alzheimer's Drug Discovery: Complete Data Flow & Tool Chain

' Define colors
skinparam rectangle {
    BackgroundColor<<database>> #E3F2FD
    BorderColor<<database>> #1976D2
    BackgroundColor<<tool>> #FFF3E0
    BorderColor<<tool>> #F57C00
    BackgroundColor<<process>> #E8F5E9
    BorderColor<<process>> #388E3C
    BackgroundColor<<output>> #F3E5F5
    BorderColor<<output>> #7B1FA2
}

' ============================================================================
' SECTION 0: SETUP
' ============================================================================
package "SECTION 0: Setup (Google Colab)" #FAFAFA {
    rectangle "Google Drive\nMount" as drive <<tool>>
    rectangle "Set Working\nDirectory" as workdir <<process>>
    rectangle "Install Libraries\n(uv pip install)" as install <<tool>>
    
    drive -down-> workdir
    workdir -down-> install
    
    note right of install
        **Libraries Installed:**
        • pandas, numpy
        • scikit-learn
        • RDKit
        • LazyPredict
        • XGBoost, LightGBM
        • matplotlib, seaborn
        • scipy
    end note
}

' ============================================================================
' SECTION 3: DATA COLLECTION
' ============================================================================
package "SECTION 3: Data Collection & Cleaning" #FAFAFA {
    
    ' Data Sources
    database "ChEMBL Database\n(UK - EMBL-EBI)" as chembl <<database>>
    
    rectangle "Raw Excel File\n7,918 compounds\n45 columns" as excel <<database>>
    
    rectangle "pandas.read_excel()\nLoad Data" as load <<tool>>
    
    ' Cleaning steps
    rectangle "Filter 1:\nIC50 only\n(1,497 rows)" as filter1 <<process>>
    rectangle "Filter 2:\nnM units only\n(1,351 rows)" as filter2 <<process>>
    rectangle "Filter 3:\nRemove nulls\n(1,319 rows)" as filter3 <<process>>
    
    ' Labeling
    rectangle "Bioactivity\nClassification\nFunction" as classify <<process>>
    
    ' Output
    rectangle "Curated Dataset\n1,319 compounds\nIC50 + SMILES + MW" as curated <<output>>
    
    rectangle "Labeled Dataset\nActive: 449\nIntermediate: 375\nInactive: 495" as labeled <<output>>
    
    chembl -down-> excel : "Downloaded\n(pre-processed)"
    excel -down-> load
    load -down-> filter1
    filter1 -down-> filter2
    filter2 -down-> filter3
    filter3 -down-> curated
    curated -down-> classify
    classify -down-> labeled
    
    note right of chembl
        **ChEMBL Provides:**
        • IC50 measurements
        • SMILES structures
        • Molecular weights
        • ChEMBL IDs
        • Assay metadata
    end note
    
    note right of classify
        **Classification Rules:**
        • Active: IC50 ≤ 1,000 nM
        • Intermediate: 1K-10K nM
        • Inactive: IC50 ≥ 10,000 nM
    end note
}

' ============================================================================
' SECTION 4: EXPLORATORY DATA ANALYSIS
' ============================================================================
package "SECTION 4: Exploratory Data Analysis" #FAFAFA {
    
    rectangle "RDKit Library\n(Chemistry)" as rdkit <<tool>>
    
    rectangle "Calculate\nLipinski Descriptors" as lipinski <<process>>
    
    rectangle "Lipinski Features:\n• MW (Molecular Weight)\n• LogP (Lipophilicity)\n• NumHDonors\n• NumHAcceptors" as lipinski_out <<output>>
    
    rectangle "pIC50\nTransformation\n-log₁₀(IC50 in M)" as pic50 <<process>>
    
    rectangle "Remove\nIntermediate Class\n(944 compounds)" as binary <<process>>
    
    rectangle "matplotlib +\nseaborn\nVisualization" as viz <<tool>>
    
    rectangle "Box Plots:\n• MW distribution\n• LogP distribution\n• pIC50 distribution\n• H-bond donors/acceptors" as plots <<output>>
    
    rectangle "scipy.stats\nMann-Whitney U Test" as stats <<tool>>
    
    rectangle "Statistical Results:\nAll p < 0.05\n(Significant!)" as pvalues <<output>>
    
    labeled -down-> rdkit
    rdkit -down-> lipinski
    lipinski -down-> lipinski_out
    lipinski_out -down-> pic50
    pic50 -down-> binary
    binary -down-> viz
    viz -down-> plots
    binary -down-> stats
    stats -down-> pvalues
    
    note right of rdkit
        **RDKit Functions:**
        • Chem.MolFromSmiles()
        • Descriptors.MolWt()
        • Descriptors.MolLogP()
        • Descriptors.NumHDonors()
        • Descriptors.NumHAcceptors()
    end note
    
    note right of pic50
        **Why Transform?**
        • IC50 spans 6 orders of magnitude
        • Log transform normalizes
        • Higher pIC50 = Better drug
        • ML works better with normal dist.
    end note
}

' ============================================================================
' SECTION 5: FEATURE ENGINEERING
' ============================================================================
package "SECTION 5: Feature Engineering (Molecular Fingerprints)" #FAFAFA {
    
    rectangle "pandas.to_csv()\nExport SMILES" as export_smiles <<tool>>
    
    rectangle "molecule.smi\n1,319 SMILES\n(tab-separated)" as smiles_file <<output>>
    
    database "PubChem\nFingerprint System\n(USA - NIH/NCBI)" as pubchem <<database>>
    
    rectangle "PaDEL-Descriptor\n(Java Tool)" as padel <<tool>>
    
    rectangle "descriptors_output.csv\n881 PubChem\nFingerprints" as fingerprints <<output>>
    
    rectangle "pandas.concat()\nMerge X + Y" as merge <<process>>
    
    rectangle "Final Dataset\n1,319 × 883\n(881 FP + MW + pIC50)" as final_data <<output>>
    
    lipinski_out -down-> export_smiles
    export_smiles -down-> smiles_file
    smiles_file -down-> padel
    pubchem -down-> padel : "Defines 881\nsubstructures"
    padel -down-> fingerprints
    fingerprints -down-> merge
    pic50 -down-> merge
    merge -down-> final_data
    
    note right of pubchem
        **PubChem Fingerprints:**
        • 881-bit binary vector
        • Bits 1-115: Element counts
        • Bits 116-263: Ring systems
        • Bits 264-459: Atom pairs
        • Bits 460-579: Environments
        • Bits 580-881: SMARTS patterns
    end note
    
    note right of padel
        **PaDEL Command:**
        java -jar PaDEL-Descriptor.jar
        -fingerprints
        -dir molecule.smi
        -file descriptors_output.csv
    end note
}

' ============================================================================
' SECTION 6: MACHINE LEARNING
' ============================================================================
package "SECTION 6: Model Building & Optimization" #FAFAFA {
    
    ' Feature Selection
    rectangle "scikit-learn\nVarianceThreshold\n(threshold=0.16)" as variance <<tool>>
    
    rectangle "Filtered Features\n881 → 178 features" as filtered <<output>>
    
    ' Train/Test Split
    rectangle "scikit-learn\ntrain_test_split\n(80/20)" as split <<tool>>
    
    rectangle "Training Set\n1,055 samples\n178 features" as train <<output>>
    
    rectangle "Test Set\n264 samples\n178 features" as test <<output>>
    
    ' Model Comparison
    rectangle "LazyPredict\nLazyRegressor\n(30+ models)" as lazy <<tool>>
    
    rectangle "Model Rankings:\n1. RandomForest\n2. HistGradientBoosting\n3. XGBoost\n4. MLPRegressor\n5. SVR" as rankings <<output>>
    
    ' Cross-Validation
    rectangle "scikit-learn\ncross_val_score\n(5-fold CV)" as cv <<tool>>
    
    rectangle "CV Results:\nRF: 0.76 ± 0.04\nHGB: 0.75 ± 0.05" as cv_results <<output>>
    
    ' Hyperparameter Tuning
    rectangle "scikit-learn\nGridSearchCV" as grid <<tool>>
    
    rectangle "Tuned Models:\n• RandomForest\n• HistGradientBoosting" as tuned <<output>>
    
    ' Ensemble
    rectangle "scikit-learn\nVotingRegressor\n(RF + HGB + SVR)" as ensemble <<tool>>
    
    rectangle "Final Model\nR² = 0.78\nRMSE = 0.58" as final_model <<output>>
    
    final_data -down-> variance
    variance -down-> filtered
    filtered -down-> split
    split -down-> train
    split -down-> test
    train -down-> lazy
    test -down-> lazy
    lazy -down-> rankings
    rankings -down-> cv
    cv -down-> cv_results
    cv_results -down-> grid
    grid -down-> tuned
    tuned -down-> ensemble
    ensemble -down-> final_model
    
    note right of variance
        **Why Remove Low Variance?**
        • Features that are always 0 or 1
        • Provide no information
        • Reduce noise & speed up training
    end note
    
    note right of lazy
        **Models Tested:**
        • Linear: Ridge, Lasso, ElasticNet
        • Trees: RF, ExtraTrees, GB
        • Boosting: XGB, LightGBM, HGB
        • SVM: SVR, NuSVR
        • Neural: MLPRegressor
        • Neighbors: KNN
        • And 20+ more...
    end note
}

' ============================================================================
' SECTION 7: RESULTS & OUTPUTS
' ============================================================================
package "SECTION 7: Results & Conclusions" #FAFAFA {
    
    rectangle "Model Performance\nCSVs" as perf_csv <<output>>
    
    rectangle "Visualization\nPDFs" as viz_pdf <<output>>
    
    rectangle "Statistical\nValidation" as validation <<output>>
    
    rectangle "Key Findings:\n• R² = 0.78 (78% variance explained)\n• RMSE = 0.58 pIC50 units\n• All descriptors significant (p<0.05)\n• Moderate overfitting in tree models\n• Ensemble improves generalization" as findings <<output>>
    
    final_model -down-> perf_csv
    final_model -down-> viz_pdf
    pvalues -down-> validation
    perf_csv -down-> findings
    viz_pdf -down-> findings
    validation -down-> findings
}

' ============================================================================
' LEGEND
' ============================================================================
legend right
    |= Color |= Meaning |
    | <back:#E3F2FD>   </back> | Database / Data Source |
    | <back:#FFF3E0>   </back> | Tool / Library |
    | <back:#E8F5E9>   </back> | Process / Transformation |
    | <back:#F3E5F5>   </back> | Output / Result |
endlegend

' ============================================================================
' KEY METRICS SUMMARY
' ============================================================================
note bottom
    **PROJECT SUMMARY**
    ═══════════════════════════════════════════════════════════════
    **Data Sources:**
    • ChEMBL (UK): Bioactivity measurements (IC50, SMILES)
    • PubChem (USA): Fingerprint system (881 substructures)
    
    **Data Pipeline:**
    7,918 compounds → 1,319 curated → 881 features → 178 selected
    
    **Best Model:**
    RandomForest & HistGradientBoosting: R² = 0.78, RMSE = 0.58
    
    **Key Tools:**
    • Python: pandas, numpy, scikit-learn
    • Chemistry: RDKit, PaDEL-Descriptor
    • ML: LazyPredict, XGBoost, LightGBM
    • Stats: scipy, matplotlib, seaborn
    
    **Real-World Impact:**
    • Predict drug potency from structure
    • Screen thousands of compounds computationally
    • Save millions in drug development costs
    • Accelerate Alzheimer's treatment discovery
end note

@enduml
